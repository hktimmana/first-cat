{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experiment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPtLHaYMJp4pIkdk7iczd4S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hktimmana/first-cat/blob/master/Experiment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IwupjFVD7VH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "e4750901-8a3b-4c5d-82f1-57e62a0c065a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "591H5uDFFJWJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1f7809a-90ba-46b8-a8a3-abe7ea9dbd45"
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2O4-q5PGnFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bc_path='/content/gdrive/My Drive/research/binary/40X/**/**/*.png'\n",
        "model_path='/content/gdrive/My Drive/research/model'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxRnWcSIFPsH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b86b4414-ce0d-4c9a-f36c-4c1ec288abcb"
      },
      "source": [
        "IMG_DIM = (224, 224)\n",
        "bc_files = glob.glob(bc_path)\n",
        "bc_data= np.array([img_to_array(load_img(img, target_size=IMG_DIM)) for img in bc_files])\n",
        "bc_labels = [fn.split('/')[-2].strip() for fn in bc_files]\n",
        "print('Train dataset shape:', bc_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train dataset shape: (1995, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "736sSUMWH64-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b1c1e93-dd40-4d61-c048-78067355154e"
      },
      "source": [
        "import numpy as np\n",
        "nb_classes=len(np.unique(bc_labels))\n",
        "bc_count=len(bc_labels)\n",
        "nb_classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KbRYWbU1dpK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "d562063c-e8a5-4c60-834f-7a5b21a6729a"
      },
      "source": [
        "import pandas as pd\n",
        "bdf = pd.DataFrame()\n",
        "#df['images']  = train_imgs\n",
        "bdf['labels']  =bc_labels\n",
        "import seaborn as sns\n",
        "sns.countplot(\"labels\",data= bdf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f75c7877860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAASR0lEQVR4nO3df6zdd13H8eeLljEQ2Q96nbOtdpEGHBNl3IwhiSLV/UClkwyy+WMVl1Tj8BdGHJo4A6IYp5OhLqmsbINlEwe6qtXZDJRo2OQOxn50zN1MoG02eqVjKohYfPvH+VQO3b393LU959zuPh/Jyf1+35/P+X7fN7nra98f53tSVUiSdChPm3QDkqSlz7CQJHUZFpKkLsNCktRlWEiSulZOuoFRWLVqVa1bt27SbUjSMeWuu+76t6qamm/sKRkW69atY2ZmZtJtSNIxJcmnFxrzNJQkqWtkYZFka5K9Se6bZ+yXklSSVW09Sa5OMpvkniRnDs3dlOSh9to0qn4lSQsb5ZHFdcB5BxeTrAXOAT4zVD4fWN9em4Fr2tyTgSuAlwJnAVckOWmEPUuS5jGysKiqDwP75hm6CngTMPyckY3ADTVwB3BiklOBc4EdVbWvqh4DdjBPAEmSRmus1yySbAT2VNUnDhpaDewaWt/dagvV59v25iQzSWbm5uaOYteSpLGFRZJnAb8K/Pootl9VW6pquqqmp6bmvfNLknSYxnlk8a3AacAnknwKWAN8LMk3AnuAtUNz17TaQnVJ0hiNLSyq6t6q+oaqWldV6xicUjqzqh4FtgGXtLuizgYer6pHgNuAc5Kc1C5sn9NqkqQxGuWtszcBHwGen2R3kksPMX078DAwC/wJ8DMAVbUPeCvw0fZ6S6tJksYoT8UvP5qeni4/wa2nss+85dsn3YKWoG/+9XuP6P1J7qqq6fnG/AS3JKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkrpGFhZJtibZm+S+odrvJvlkknuS/HmSE4fG3pxkNsmDSc4dqp/XarNJLh9Vv5KkhY3yyOI64LyDajuAM6rqRcC/AG8GSHI6cBHwwvaeP06yIskK4I+A84HTgYvbXEnSGI0sLKrqw8C+g2p/V1X72+odwJq2vBG4uar+u6r+FZgFzmqv2ap6uKq+DNzc5kqSxmiS1yx+Evibtrwa2DU0trvVFqo/QZLNSWaSzMzNzY2gXUlaviYSFkl+DdgP3Hi0tllVW6pquqqmp6amjtZmJUnAynHvMMlPAD8IbKiqauU9wNqhaWtajUPUJUljMtYjiyTnAW8CXl1VXxwa2gZclOQZSU4D1gP/DHwUWJ/ktCTHMbgIvm2cPUuSRnhkkeQm4BXAqiS7gSsY3P30DGBHEoA7quqnq+r+JO8DdjI4PXVZVX2lbecNwG3ACmBrVd0/qp4lSfMbWVhU1cXzlK89xPy3AW+bp74d2H4UW5MkPUl+gluS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXSMLiyRbk+xNct9Q7eQkO5I81H6e1OpJcnWS2ST3JDlz6D2b2vyHkmwaVb+SpIWN8sjiOuC8g2qXA7dX1Xrg9rYOcD6wvr02A9fAIFyAK4CXAmcBVxwIGEnS+IwsLKrqw8C+g8obgevb8vXABUP1G2rgDuDEJKcC5wI7qmpfVT0G7OCJASRJGrFxX7M4paoeacuPAqe05dXArqF5u1ttobokaYwmdoG7qgqoo7W9JJuTzCSZmZubO1qblSQx/rD4bDu9RPu5t9X3AGuH5q1ptYXqT1BVW6pquqqmp6amjnrjkrScjTsstgEH7mjaBNw6VL+k3RV1NvB4O111G3BOkpPahe1zWk2SNEYrR7XhJDcBrwBWJdnN4K6mtwPvS3Ip8GngdW36duBVwCzwReD1AFW1L8lbgY+2eW+pqoMvmkuSRmxkYVFVFy8wtGGeuQVctsB2tgJbj2JrkqQnyU9wS5K6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdU0kLJL8YpL7k9yX5KYkxyc5LcmdSWaT/GmS49rcZ7T12Ta+bhI9S9JyNvawSLIa+DlguqrOAFYAFwG/A1xVVc8DHgMubW+5FHis1a9q8yRJYzSp01ArgWcmWQk8C3gEeCVwSxu/HrigLW9s67TxDUkyxl4ladkbe1hU1R7gSuAzDELiceAu4PNVtb9N2w2sbsurgV3tvfvb/OcevN0km5PMJJmZm5sb7S8hScvMosIiye2LqS1yWycxOFo4Dfgm4OuA8w5nW8OqaktVTVfV9NTU1JFuTpI0ZOWhBpMcz+A00ar2j/yB0z/P4av/5/9kfR/wr1U11/bxAeDlwIlJVrajhzXAnjZ/D7AW2N1OW50AfO4w9y1JOgy9I4ufYnCK6AXt54HXrcAfHuY+PwOcneRZ7drDBmAn8CHgwjZnU9sHwLa2Thv/YFXVYe5bknQYDnlkUVXvAN6R5Ger6p1HY4dVdWeSW4CPAfuBjwNbgL8Gbk7ym612bXvLtcB7kswC+xjcOSVJGqNDhsUBVfXOJN8FrBt+T1XdcDg7raorgCsOKj8MnDXP3C8Brz2c/UiSjo5FhUWS9wDfCtwNfKWVCzissJAkHVsWFRbANHC61wokaXla7Ocs7gO+cZSNSJKWrsUeWawCdib5Z+C/DxSr6tUj6UqStKQsNix+Y5RNSJKWtsXeDfUPo25EkrR0LfZuqP9gcPcTwHHA04EvVNVzRtWYJGnpWOyRxdcfWG6fut4InD2qpiRJS8uTfupsDfwFcO4I+pEkLUGLPQ31mqHVpzH43MWXRtKRJGnJWezdUD80tLwf+BSDU1GSpGVgsdcsXj/qRiRJS9div/xoTZI/T7K3vd6fZM2om5MkLQ2LvcD9bgbfK/FN7fWXrSZJWgYWGxZTVfXuqtrfXtcBfnepJC0Tiw2LzyX5sSQr2uvH8KtNJWnZWGxY/CTwOuBR4BEGX2/6EyPqSZK0xCz21tm3AJuq6jGAJCcDVzIIEUnSU9xijyxedCAoAKpqH/Di0bQkSVpqFhsWT0ty0oGVdmSx2KMSSdIxbrH/4P8e8JEkf9bWXwu8bTQtLQ0v+WW/XlxPdNfvXjLpFqSJWNSRRVXdALwG+Gx7vaaq3nO4O01yYpJbknwyyQNJXpbk5CQ7kjzUfp7U5ibJ1Ulmk9yT5MzD3a8k6fAs+qmzVbWzqv6wvXYe4X7fAfxtVb0A+A7gAeBy4PaqWg/c3tYBzgfWt9dm4Joj3Lck6Ul60o8oP1JJTgC+G7gWoKq+XFWfZ/BgwuvbtOuBC9ryRuCG9mj0O4ATk5w65rYlaVkbe1gApwFzwLuTfDzJu5J8HXBKVT3S5jwKnNKWVwO7ht6/u9W+RpLNSWaSzMzNzY2wfUlafiYRFiuBM4FrqurFwBf46iknYPAFS3z1a1wXpaq2VNV0VU1PTfkkEkk6miYRFruB3VV1Z1u/hUF4fPbA6aX2c28b3wOsHXr/mlaTJI3J2MOiqh4FdiV5fittAHYyeKrtplbbBNzalrcBl7S7os4GHh86XSVJGoNJfbDuZ4EbkxwHPAy8nkFwvS/JpcCnGTyLCmA78CpgFvhimytJGqOJhEVV3c3ge7wPtmGeuQVcNvKmJEkLmsQ1C0nSMcawkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSuiYWFklWJPl4kr9q66cluTPJbJI/TXJcqz+jrc+28XWT6lmSlqtJHln8PPDA0PrvAFdV1fOAx4BLW/1S4LFWv6rNkySN0UTCIska4AeAd7X1AK8EbmlTrgcuaMsb2zptfEObL0kak0kdWfwB8Cbgf9v6c4HPV9X+tr4bWN2WVwO7ANr4423+10iyOclMkpm5ublR9i5Jy87YwyLJDwJ7q+quo7ndqtpSVdNVNT01NXU0Ny1Jy97KCezz5cCrk7wKOB54DvAO4MQkK9vRwxpgT5u/B1gL7E6yEjgB+Nz425ak5WvsRxZV9eaqWlNV64CLgA9W1Y8CHwIubNM2Abe25W1tnTb+waqqMbYsScveUvqcxa8Ab0wyy+CaxLWtfi3w3FZ/I3D5hPqTpGVrEqeh/l9V/T3w9235YeCseeZ8CXjtWBuTJH2NpXRkIUlaogwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpa+xhkWRtkg8l2Znk/iQ/3+onJ9mR5KH286RWT5Krk8wmuSfJmePuWZKWu0kcWewHfqmqTgfOBi5LcjpwOXB7Va0Hbm/rAOcD69trM3DN+FuWpOVt7GFRVY9U1cfa8n8ADwCrgY3A9W3a9cAFbXkjcEMN3AGcmOTUMbctScvaRK9ZJFkHvBi4Ezilqh5pQ48Cp7Tl1cCuobftbjVJ0phMLCySPBt4P/ALVfXvw2NVVUA9ye1tTjKTZGZubu4odipJmkhYJHk6g6C4sao+0MqfPXB6qf3c2+p7gLVDb1/Tal+jqrZU1XRVTU9NTY2ueUlahiZxN1SAa4EHqur3h4a2AZva8ibg1qH6Je2uqLOBx4dOV0mSxmDlBPb5cuDHgXuT3N1qvwq8HXhfkkuBTwOva2PbgVcBs8AXgdePt11J0tjDoqr+EcgCwxvmmV/AZSNtSpJ0SH6CW5LUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqeuYCYsk5yV5MMlskssn3Y8kLSfHRFgkWQH8EXA+cDpwcZLTJ9uVJC0fx0RYAGcBs1X1cFV9GbgZ2DjhniRp2Vg56QYWaTWwa2h9N/DS4QlJNgOb2+p/JnlwTL0tB6uAf5t0E0tBrtw06Rb0RP59HnBFjnQL37LQwLESFl1VtQXYMuk+noqSzFTV9KT7kObj3+d4HCunofYAa4fW17SaJGkMjpWw+CiwPslpSY4DLgK2TbgnSVo2jonTUFW1P8kbgNuAFcDWqrp/wm0tJ57e01Lm3+cYpKom3YMkaYk7Vk5DSZImyLCQJHUZFlpQkq8kuTvJJ5J8LMl3TbonKUklee/Q+sokc0n+apJ9PdUdExe4NTH/VVXfCZDkXOC3ge+ZbEsSXwDOSPLMqvov4PvxVvqR88hCi/Uc4LFJNyE124EfaMsXAzdNsJdlwbDQoTyznYb6JPAu4K2TbkhqbgYuSnI88CLgzgn385TnaSgdyvBpqJcBNyQ5o7zfWhNWVfckWcfgqGL7ZLtZHjyy0KJU1UcYPLBtatK9SM024Eo8BTUWHlloUZK8gMGn5z836V6kZivw+aq6N8krJt3MU51hoUN5ZpK723KATVX1lUk2JB1QVbuBqyfdx3Lh4z4kSV1es5AkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIR2mJP/ZGV+X5L4nuc3rklx4ZJ1JR59hIUnqMiykI5Tk2Ulub9/5cW+SjUPDK5PcmOSBJLckeVZ7z0uS/EOSu5LcluTUebb79iQ7k9yT5Mqx/ULSPAwL6ch9CfjhqjoT+F7g95KkjT0f+OOq+jbg34GfSfJ04J3AhVX1EgaPrXjb8AaTPBf4YeCFVfUi4DfH86tI8/NxH9KRC/BbSb4b+F9gNXBKG9tVVf/Ult8L/Bzwt8AZwI6WKSuARw7a5uMMQuja9g1wfgucJsqwkI7cjzJ4Gu9Lqup/knwKOL6NHfw8nWIQLvdX1csW2mBV7U9yFrABuBB4A/DKo924tFiehpKO3AnA3hYU3wt8y9DYN7fvAgH4EeAfgQeBqQP1JE9P8sLhDSZ5NnBCVW0HfhH4jlH/EtKheGQhHbkbgb9Mci8wA3xyaOxB4LIkW4GdwDVV9eV2e+zVSU5g8N/hHwD3D73v64Fb2zfBBXjjGH4PaUE+dVaS1OVpKElSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1PV/rG6wS04AC7EAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJDpl2Rc1gCt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d84ac091-6e27-4121-eba1-9fcc05a22f37"
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "bc_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(bc_labels),\n",
        "                                                 bc_labels)\n",
        "bc_weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.596     , 0.72810219])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5r-_3Mx18y1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(bc_data, bc_labels, test_size=0.20, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ0-49O91koD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "y_train=le.fit_transform(y_train)\n",
        "y_test=le.fit_transform(y_test)\n",
        "# convert class vectors to binary class matrices\n",
        "#y_train = np_utils.to_categorical(le.fit_transform(y_train), nb_classes)\n",
        "#y_test = np_utils.to_categorical(le.fit_transform(y_test), nb_classes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmhSRdjC4p-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "141e8440-a5b2-4f4c-aaa5-7580eed74bf1"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "batchsize=32\n",
        "# create generators  - training data will be augmented images\n",
        "\n",
        "v_generator = ImageDataGenerator(rescale=1./255)\n",
        "t_generator = ImageDataGenerator(rescale=1./255,width_shift_range=0.1,height_shift_range=0.1,rotation_range=15,zoom_range=0.1 )\n",
        "\n",
        "#balgen = BalancedDataGenerator(train_imgs, Y_train,traindatagenerator, batch_size=32)\n",
        "train_generator=t_generator.flow(X_train, y_train, batch_size=batchsize) \n",
        "validation_generator=v_generator.flow(X_test, y_test,batch_size=batchsize)\n",
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 0 0 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 1 1 1\n",
            " 1 1 0 1 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0\n",
            " 1 0 1 0 1 1 1 0 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 0 0 1 1 0 1 1 1 1 1\n",
            " 1 0 0 0 1 1 0 1 0 0 1 1 0 1 0 1 0 1 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 1 1 1 1\n",
            " 0 0 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1\n",
            " 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1\n",
            " 1 0 0 1 0 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1\n",
            " 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1\n",
            " 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 0 0 1 0 0 1 1\n",
            " 1 0 1 1 0 1 0 0 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot1t72O85YiR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1a26fff3-5959-46d3-ef6a-d8528e14d57c"
      },
      "source": [
        "batch_size=32\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "early_stopping = EarlyStopping(monitor='accuracy', mode='max', patience=20, verbose=2)\n",
        "model_checkpoint = ModelCheckpoint(model_path+'/vgg16_breakhis_TL_fine.h5', save_best_only=True, verbose=2)\n",
        "history1= model.fit_generator(train_generator, steps_per_epoch=int(train_generator.n/batch_size), \n",
        "                    epochs=50, validation_data=validation_generator, class_weight=bc_weights,\n",
        "                    validation_steps=int(validation_generator.n/batch_size),callbacks=[early_stopping, model_checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "49/49 [==============================] - 53s 1s/step - loss: 0.2714 - accuracy: 0.8830 - val_loss: 0.1068 - val_accuracy: 0.8698\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.10676, saving model to /content/gdrive/My Drive/research/model/vgg16_breakhis_TL_fine.h5\n",
            "Epoch 2/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.2293 - accuracy: 0.9092 - val_loss: 0.2515 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.10676\n",
            "Epoch 3/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.2097 - accuracy: 0.9118 - val_loss: 0.0497 - val_accuracy: 0.8910\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.10676 to 0.04972, saving model to /content/gdrive/My Drive/research/model/vgg16_breakhis_TL_fine.h5\n",
            "Epoch 4/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.1570 - accuracy: 0.9405 - val_loss: 0.0530 - val_accuracy: 0.9019\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.04972\n",
            "Epoch 5/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.1398 - accuracy: 0.9495 - val_loss: 0.3866 - val_accuracy: 0.9155\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.04972\n",
            "Epoch 6/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.1385 - accuracy: 0.9469 - val_loss: 0.3743 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.04972\n",
            "Epoch 7/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.1684 - accuracy: 0.9373 - val_loss: 0.1668 - val_accuracy: 0.9264\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.04972\n",
            "Epoch 8/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.1383 - accuracy: 0.9457 - val_loss: 0.7030 - val_accuracy: 0.9019\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.04972\n",
            "Epoch 9/50\n",
            "49/49 [==============================] - 51s 1s/step - loss: 0.1066 - accuracy: 0.9591 - val_loss: 0.2774 - val_accuracy: 0.9292\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.04972\n",
            "Epoch 10/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.1030 - accuracy: 0.9578 - val_loss: 0.3297 - val_accuracy: 0.9237\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.04972\n",
            "Epoch 11/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.0846 - accuracy: 0.9694 - val_loss: 0.1686 - val_accuracy: 0.9373\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.04972\n",
            "Epoch 12/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.1299 - accuracy: 0.9532 - val_loss: 0.1117 - val_accuracy: 0.9128\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.04972\n",
            "Epoch 13/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.0971 - accuracy: 0.9681 - val_loss: 0.0080 - val_accuracy: 0.9373\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.04972 to 0.00805, saving model to /content/gdrive/My Drive/research/model/vgg16_breakhis_TL_fine.h5\n",
            "Epoch 14/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.0942 - accuracy: 0.9668 - val_loss: 0.3678 - val_accuracy: 0.9167\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.00805\n",
            "Epoch 15/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.0765 - accuracy: 0.9751 - val_loss: 0.0170 - val_accuracy: 0.9428\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.00805\n",
            "Epoch 16/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.0888 - accuracy: 0.9679 - val_loss: 0.3022 - val_accuracy: 0.9428\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.00805\n",
            "Epoch 17/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.0995 - accuracy: 0.9629 - val_loss: 0.0314 - val_accuracy: 0.9319\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.00805\n",
            "Epoch 18/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.0491 - accuracy: 0.9827 - val_loss: 8.8220e-04 - val_accuracy: 0.9537\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.00805 to 0.00088, saving model to /content/gdrive/My Drive/research/model/vgg16_breakhis_TL_fine.h5\n",
            "Epoch 19/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.1015 - accuracy: 0.9668 - val_loss: 0.6356 - val_accuracy: 0.9101\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.00088\n",
            "Epoch 20/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.0567 - accuracy: 0.9788 - val_loss: 0.3490 - val_accuracy: 0.9210\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00088\n",
            "Epoch 21/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.0289 - accuracy: 0.9879 - val_loss: 0.1602 - val_accuracy: 0.9428\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00088\n",
            "Epoch 22/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.0294 - accuracy: 0.9917 - val_loss: 1.0737 - val_accuracy: 0.9210\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.00088\n",
            "Epoch 23/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.0560 - accuracy: 0.9809 - val_loss: 0.1062 - val_accuracy: 0.9428\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.00088\n",
            "Epoch 24/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.0417 - accuracy: 0.9853 - val_loss: 0.1182 - val_accuracy: 0.9482\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.00088\n",
            "Epoch 25/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.0311 - accuracy: 0.9891 - val_loss: 0.0785 - val_accuracy: 0.9482\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00088\n",
            "Epoch 26/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.0451 - accuracy: 0.9808 - val_loss: 0.1523 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00088\n",
            "Epoch 27/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.0394 - accuracy: 0.9834 - val_loss: 0.0083 - val_accuracy: 0.9167\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.00088\n",
            "Epoch 28/50\n",
            "49/49 [==============================] - 51s 1s/step - loss: 0.0841 - accuracy: 0.9705 - val_loss: 0.4334 - val_accuracy: 0.9210\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00088\n",
            "Epoch 29/50\n",
            "49/49 [==============================] - 51s 1s/step - loss: 0.0397 - accuracy: 0.9847 - val_loss: 0.3859 - val_accuracy: 0.9482\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00088\n",
            "Epoch 30/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.0184 - accuracy: 0.9923 - val_loss: 0.0204 - val_accuracy: 0.9482\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.00088\n",
            "Epoch 31/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.0247 - accuracy: 0.9930 - val_loss: 0.1136 - val_accuracy: 0.9346\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00088\n",
            "Epoch 32/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.0422 - accuracy: 0.9885 - val_loss: 0.0436 - val_accuracy: 0.9292\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00088\n",
            "Epoch 33/50\n",
            "49/49 [==============================] - 52s 1s/step - loss: 0.0218 - accuracy: 0.9930 - val_loss: 0.0683 - val_accuracy: 0.9619\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00088\n",
            "Epoch 34/50\n",
            "14/49 [=======>......................] - ETA: 32s - loss: 0.0125 - accuracy: 0.9933"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIS6uQEhxsDA",
        "colab_type": "text"
      },
      "source": [
        "Experiment with Mandeley dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_zeXEszgBaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls /content/gdrive/My\\ Drive/research/mendeley/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8VBm-XzKaS1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2b932af5-fc43-45f3-b856-ff9b7110902f"
      },
      "source": [
        "'''\n",
        "%cd /content/gdrive/My\\ Drive/research/\n",
        "!rm  b63daee9-78de-4122-8475-9b3aa22ffd64\n",
        "!wget https://data.mendeley.com/datasets/wmy84gzngw/1/files/b63daee9-78de-4122-8475-9b3aa22ffd64/us-dataset.zip\n",
        "!unzip us-dataset.zip\n",
        "#Convert bmp to png\n",
        "from PIL import Image\n",
        "import glob,shutil\n",
        "path='/content/gdrive/My Drive/research/'\n",
        "src_dir='originals/'\n",
        "dest_dir='mendeley/'\n",
        "files=glob.glob('/content/gdrive/My Drive/research/mendeley/**/*.png')\n",
        "for fn in files:\n",
        "  fn_1=fn.split('/')[-1].split('.')[0]\n",
        "  fn_2=fn.split('/')[-2]\n",
        "  #print(path+dest_dir+fn_2+'/'+fn_1+'.png')\n",
        "  Image.open(fn).resize( (224, 224) ).save( fn, 'png')\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n%cd /content/gdrive/My\\\\ Drive/research/\\n!rm  b63daee9-78de-4122-8475-9b3aa22ffd64\\n!wget https://data.mendeley.com/datasets/wmy84gzngw/1/files/b63daee9-78de-4122-8475-9b3aa22ffd64/us-dataset.zip\\n!unzip us-dataset.zip\\n#Convert bmp to png\\nfrom PIL import Image\\nimport glob,shutil\\npath='/content/gdrive/My Drive/research/'\\nsrc_dir='originals/'\\ndest_dir='mendeley/'\\nfiles=glob.glob('/content/gdrive/My Drive/research/mendeley/**/*.png')\\nfor fn in files:\\n  fn_1=fn.split('/')[-1].split('.')[0]\\n  fn_2=fn.split('/')[-2]\\n  #print(path+dest_dir+fn_2+'/'+fn_1+'.png')\\n  Image.open(fn).resize( (224, 224) ).save( fn, 'jpg')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hAcd4z4jZEd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0a894b4-6b69-449e-8e59-b25366d32d7b"
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
        "%matplotlib inline\n",
        "file_path='/content/gdrive/My Drive/research/mendeley/**/*.png'\n",
        "\n",
        "IMG_DIM = (224, 224)\n",
        "\n",
        "\n",
        "files = glob.glob(file_path)\n",
        "data = np.array([img_to_array(load_img(img, target_size=IMG_DIM)) for img in files])\n",
        "labels = [fn.split('/')[-2].strip() for fn in files]\n",
        "print('Dataset shape:', data.shape) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset shape: (250, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K8d4o33kSfa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f020364-f2fa-40f2-8078-c4b06f9378b3"
      },
      "source": [
        "import numpy as np\n",
        "nb_classes=len(np.unique(labels))\n",
        "train_count=len(labels)\n",
        "nb_classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5cTJ1H_kodC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "aabc4196-6823-40e7-d3f6-2e0375205d67"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame()\n",
        "#df['images']  = train_imgs\n",
        "df['labels']  =labels\n",
        "import seaborn as sns\n",
        "sns.countplot(\"labels\",data= df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f75fd590400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5WoOnnKljFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_oyKvBik0po",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5467fe3a-17a4-49ce-d776-966387e51546"
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(labels),\n",
        "                                                 labels)\n",
        "class_weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.25      , 0.83333333])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rgWJBy1lgFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.20, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDasOeThpQGn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f0810bae-db6c-4c5e-9d06-4dc497b1349a"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "y_train=le.fit_transform(y_train)\n",
        "y_test=le.fit_transform(y_test)\n",
        "# convert class vectors to binary class matrices\n",
        "#y_train = np_utils.to_categorical(le.fit_transform(y_train), nb_classes)\n",
        "#y_test = np_utils.to_categorical(le.fit_transform(y_test), nb_classes)\n",
        "k"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
              "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "       1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54lPNnoqlAy0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2212db9a-2d18-4869-f5a0-52ceaefcbac8"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "batchsize=32\n",
        "# create generators  - training data will be augmented images\n",
        "\n",
        "validationdatagenerator = ImageDataGenerator(rescale=1./255)\n",
        "traindatagenerator = ImageDataGenerator(rescale=1./255,width_shift_range=0.1,height_shift_range=0.1,rotation_range=15,zoom_range=0.1 )\n",
        "\n",
        "#balgen = BalancedDataGenerator(train_imgs, Y_train,traindatagenerator, batch_size=32)\n",
        "train_generator=traindatagenerator.flow(X_train, y_train, batch_size=batchsize) \n",
        "validation_generator=validationdatagenerator.flow(X_test, y_test,batch_size=batchsize)\n",
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1 1 0 1 1 0 1 0\n",
            " 1 1 1 1 0 1 1 1 0 1 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2DsWHYJmEWN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "66b863d2-5e23-4c0b-fd81-b9cb99d3d10e"
      },
      "source": [
        "#All Necessary Imports\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from keras.layers import merge, Input\n",
        "from keras.models import Model\n",
        "from keras.utils import np_utils\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.applications import vgg16\n",
        "from keras.models import Model\n",
        "import keras\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(tf.distribute.cluster_resolver.TPUClusterResolver())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.43.64.194:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.43.64.194:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ig3wyOLImM3Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "outputId": "5de72a68-68f8-422f-e3c6-5992f0810d91"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "vgg16_model = VGG16(weights=\"imagenet\", include_top=True)\n",
        " \n",
        "    #visualize layers\n",
        "#print(\"VGG16 model layers\")\n",
        "#for i, layer in enumerate(vgg16_model.layers):\n",
        "#    print(i, layer.name, layer.output_shape)\n",
        "from keras.layers import Dense, Dropout, Reshape\n",
        "from keras.models import Model, load_model\n",
        "# (2) remove the top layer\n",
        "with strategy.scope():\n",
        "  base_model = Model(input=vgg16_model.input, \n",
        "                    output=vgg16_model.get_layer(\"block5_pool\").output)\n",
        "  # (3) attach a new top layer\n",
        "  base_out = base_model.output\n",
        "  base_out = Reshape((25088,))(base_out)\n",
        "  top_fc1 = Dense(256, activation=\"relu\")(base_out)\n",
        "  top_fc1 = Dropout(0.5)(top_fc1)\n",
        "  # output layer: (None, 5)\n",
        "  top_preds = Dense(1, activation=\"sigmoid\")(top_fc1)\n",
        "  # (4) freeze weights until the last but one convolution layer (block4_pool)\n",
        "  for layer in base_model.layers[0:14]:\n",
        "      #print(layer.name)\n",
        "      layer.trainable = False\n",
        "  model = Model(input=base_model.input, output=top_preds)\n",
        "  model.compile(optimizer='adam', loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"bl...)`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "reshape_4 (Reshape)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 256)               6422784   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 21,137,729\n",
            "Trainable params: 13,502,465\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfuWt8l8mrZd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "b83747e0-68ae-4aae-d3c9-de5a82d50b0c"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "early_stopping = EarlyStopping(monitor='accuracy', mode='max', patience=3, verbose=2)\n",
        "model_checkpoint = ModelCheckpoint(model_path+'/vgg16_mendeley_TL_fine.h5', save_best_only=True, verbose=2)\n",
        "history= model.fit_generator(train_generator, steps_per_epoch=int(train_generator.n), \n",
        "                    epochs=10, validation_data=validation_generator, class_weight=class_weights,\n",
        "                    validation_steps=int(validation_generator.n),callbacks=[early_stopping, model_checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "200/200 [==============================] - 193s 965ms/step - loss: 0.0327 - accuracy: 0.9913 - val_loss: 2.0584e-10 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00000, saving model to /content/gdrive/My Drive/research/model/vgg16_mendeley_TL_fine.h5\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 192s 960ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 1.1253e-06 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.00000\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 192s 961ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 1.5808e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.00000\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 193s 965ms/step - loss: 0.0172 - accuracy: 0.9963 - val_loss: 3.7620e-04 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.00000\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 193s 963ms/step - loss: 0.0553 - accuracy: 0.9881 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.00000\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 193s 964ms/step - loss: 0.0475 - accuracy: 0.9900 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.00000\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}